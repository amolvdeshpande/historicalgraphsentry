%%%%%%%%%%%%%%%%%%%% author.tex %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% template for Encyclopedia articles
%
%%%%%%%%%%%%%%%% Springer %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


% RECOMMENDED %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\documentclass[graybox, natbib, nosecnum, twocolumn]{svmult}
\documentclass{svjour3}
\usepackage[english]{babel}
\usepackage[utf8x]{inputenc}
\usepackage[T1]{fontenc}

%% Sets page size and margins
\usepackage[a4paper,top=3cm,bottom=2cm,left=3cm,right=3cm,marginparwidth=1.75cm]{geometry}

%% Useful packages
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage[colorinlistoftodos]{todonotes}
\usepackage[colorlinks=true, allcolors=blue]{hyperref}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

\title{Historical Graph Data Management}
% Use \titlerunning{Short Title} for an abbreviated version of
% your contribution title if the original one is too long
\author{Udayan Khurana and Amol Deshpande}
% Use \authorrunning{Short Title} for an abbreviated version of
% your contribution title if the original one is too long
\institute{Udayan Khurana
		\at IBM Research AI, TJ Watson Research Center, Yorktown Heights New York NY, USA \\\email{ukhurana@us.ibm.com}
		\and
		Amol Deshpande
		\at Computer Science Department, University of Maryland, College Park MD, USA \\\email{amol@cs.umd.edu}
		}
%
% Use the package "url.sty" to avoid
% problems with special characters
% used in your e-mail or web address
%
\maketitle

\begin{abstract}
Your abstract.
\end{abstract}

\section{Introduction}

Analysis of history of networks presents fascinating insights into ...

For many years, graph analytics was focused on analyzing static snapshots of graphs. Included SNA, ....

Hence much of the graph database literature has focused on maintaining static graphs efficiently. 

However in recent years there is a rise of interest in analyzing evolution, .. temporal properties ...etc. Also due to higher availability of temporally annotated graph data.

This has fueled an increase of research in historical graph data management, which is still going on. 

Historical Graph DM extends the challenges of graph data management and temporal DM, but also presents unique challenges due to a combination of both. 

We discuss some interesting aspects..



\section{Storage and Retrieval}
What are the challenges?

Motivate why snapshot retrieval is the most basic operation. 

Then discuss other kinds of retrieval and what storage is best for those

\section{Historical Graph Analytics}


~\cite{khurana2013efficient}~\cite{macko2015llama}~\cite{han2014chronos}~\cite{khurana2016storing}

\section{Definitions}
Real world graphs often evolve over time, with vertices and edges continually being added or deleted, and their attribute values being frequently updated. Examples of such graphs include phone-call graphs generated by telecommunication service providers, message graphs from social networking sites, and mention-activity graphs formed by Twitter users mentioning one another in their tweets. Analyzing these temporal graphs is crucial for gaining insights relevant to real-time decision making.

There are two somewhat orthogonal challenges here, that have resulted in two distinct bodies of work. First, there is often interest in doing {\em temporal analysis} over historical traces of graphs, often called {\em time-evolving graphs} or {\em historical graphs}; examples of such analysis tasks include network evolution, historical queries, and many others. Here the main computational challenges include storing very large volumes of historical data compactly, and retrieving the data needed for any specific temporal analysis task or historical query efficiently. There is also a need for better and more user-friendly high-level interfaces for specifying complex analytical tasks.
Second, there is a need to do {\em real-time analytics on the streaming data} as it is being generated; here the scope of the analysis typically only includes the latest snapshot or the snapshots from a recent window. The key challenge here is to be able to deal with the high rate at which the data is often generated. Although these topics have received relatively less attention compared to static graph analysis,
both of them have seen a flurry of activity in the recent years that we review in this chapter.




%Main Text
\section{Overview}
This document is intended as a template and guide for the preparation of articles to an encyclopedia, using latex. Contributions should in general follow the usual scheme, "Synonyms, Definitions, Main text (split into various sections with heads and subheads chosen by authors), Conclusions, Cross-references and References", although circumstances might indicate a deviation from this. 
{\bf Footnotes should not be used}!


We first provide an overview of the existing temporal graph systems. We remark that while systems for incremental iterative data flows (see Section~\ref{incremental}), such as Naiad~\cite{naiad} and Stratosphere~\cite{stratosphere}, can also be used for processing dynamic graphs, they are not specially
designed for processing graphs. Also, several recent works have investigated, from a graph database perspective, the problems of storing and retrieving large-scale evolving graphs~\cite{Mondal2012,RenLKZC11:QueryEvolveGraph}; however they do not consider complex graph analytics, such as influence analysis or community detection algorithms, as the graph engines surveyed in this section do.

\vspace{2mm}

\noindent{\bf Computation Model.} In all of the systems that we survey, a temporal graph is viewed as a continuous stream of graph updates. A graph update can be an addition or a deletion of a vertex or an edge, or it can also be an update of an attribute associated with a node or an edge. Of the systems discussed here, Kineograph~\cite{kineograph}, Chronos~\cite{chronos}, DeltaGraph~\cite{KhuranaD13:HistoricGraph}, and LLAMA~\cite{llama}, all support general graph updates, whereas TIDE~\cite{tide} focuses on addition of vertices and edges in the context of dynamic interaction graphs, in which new interactions (edges) are continually added over time.

The frequent change of a temporal graph poses a significant challenge to algorithm design, because the overwhelming majority of graph algorithms assume static graph structures. One would have to design special algorithms for each application to accommodate the dynamic aspects of graphs. To support general-purpose computations, most of the temporal graph systems adopt a strategy to separate graph updates from graph computation. More specifically, although updates are continually applied to a temporal graph, graph computation is only performed on a sequence of successive \emph{static} views of the temporal graph. For simplicity, most systems adopt a \emph{discretized-time} approach, so that time domain is set of natural numbers, i.e., $t\in \mathcal{N}$. We use $GV_t$ to denote the static view of a temporal graph $G$ at time $t$. An analytic function $F$ applied to a temporal graph $G$ at time $t$ is actually applied to $GV_t$, with the result $F(GV_{t})$. As time advances to $t'$, the result is updated to $F(GV_{t'})$ either by computing it from scratch on $GV_{t'}$ or by incrementally updating the result from $F(GV_{t})$ to $F(GV_{t'})$.

Kineograph and TIDE both focus on point-in-time analysis that continually delivers the up-to-date results $F(GV_{t_{now}})$, where $t_{now}$ is the current time (which is constantly changing); on the other hand, Chronos, DeltaGraph, and LLAMA are designed for analysis within a time range, i.e., computing results over a series of static views within a time range.

The separation of graph update and graph computation not only allows existing algorithms designed for static graphs to be used for analyzing temporal graphs, but also enables the same familiar computation interface in existing static graph processing systems to be used for temporal graphs. In fact, TIDE employs the message passing-based vertex-centric programming model like in Pregel~\cite{pregel} for analyzing dynamic graphs, while Kineograph and Chronos use the vertex-centric scatter-gather model (like the GAS model of GraphLab~\cite{graphlab}) in either a pull mode or a push mode. In addition, Chronos can also support the edge-centric model proposed in X-Stream~\cite{xstream}.

\vspace{2mm}

\noindent{\bf Static Views of Temporal Graphs.} The static view of a temporal graph, however, can be defined differently depending on the application requirements. The most straightforward definition is a \emph{snapshot}. A \emph{snapshot} of a temporal graph $G$ at time $t$, denoted as $G_t$, is defined as the static graph formed by applying all the graph updates before $t$. Chronos, DeltaGraph, LLAMA, and Kineograph all adopt this snapshot definition of static view for temporal or streaming graph analysis. However, the snapshot model has two major drawbacks: 1) the ever-increasing size of a snapshot, especially for insertion-heavy graph updates, and 2) the growing reflection of the out-of-date characteristics of the temporal graph, due to the swelling proportion of the stale data in a snapshot. To address these drawbacks, TIDE proposes a novel \emph{probabilistic-edge-decay} (PED) model to generate static views of temporal graphs. More details of this model are provided in Section~\ref{sec:tide}.

\vspace{2mm}

\noindent{\bf Incremental Computation.} To guarantee the timeliness of analysis, systems for dynamic graphs need to continually update results as time advances. The naive way is to recompute on a new static view from scratch, which is obviously expensive. Given the significant overlap of graph structures between two successive static views, is it possible to exploit the results at $t$ to more efficiently generate results at $t+1$? The answer is yes, for iterative algorithms, such as Katz centrality~\cite{kcentral} and PageRank~\cite{pagerank}. More specifically, the incremental computation can use the ending vertex and edge states at time $t$ as the starting states for the iterative computation at time $t+1$. These improved starting states can lead to faster convergence. For some single-source shortest path algorithms~\cite{sssp}, such incremental computation is also possible if only edge insertions (deletions) are allowed. Unfortunately, some algorithms do not work correctly under this incremental scheme~\cite{dynamicgraph}, so that recomputation from scratch is required.

Several of the systems that we survey support incremental computation for dynamic graph analysis, among which Chronos exploits this technique more heavily (for details, see Section~\ref{sec:chronos}).


Broadly speaking the focus of this work is on providing the ability to analyze and to reason over the entire history of 
the changes to a graph. There are many different types of analyses that may be of interest. 
For example, an analyst may wish to study the evolution of well-studied static graph properties such
as centrality measures, density, conductance, etc., over time. Another approach is through the search and 
discovery of temporal patterns, where the events that constitute the pattern are spread out over time. 
Comparative analysis, such as juxtaposition of a statistic over time, or perhaps, computing 
aggregates such as \textit{max} or \textit{mean} over time, possibly gives another style of knowledge discovery 
into temporal graphs. Most of all, a primitive notion of just being able to access past states of the graphs 
and performing simple static graph analytics, empowers a data scientist with the capacity to 
perform analysis in arbitrary and unconventional patterns.

Supporting such a diverse set of temporal analytics and querying over large volumes of historical graph data 
requires addressing several data management challenges. Specifically, we need techniques for storing
the historical information in a compact manner, while allowing a user to retrieve graph snapshots as of any
time point in the past or the evolution history of a specific node or a specific neighborhood. Further the
data must be stored and queried in a distributed fashion to handle the increasing scale of the data.
We must also develop an expressive, high-level, easy-to-use programming framework that will allow users to 
specify complex temporal graph analysis tasks, while ensuring that the specified tasks can be executed efficiently 
in a data-parallel fashion across a cluster.

\subsection{Chronos}\label{sec:chronos}

%Different from Kineograph and TIDE which focus on point-in-time graph analysis, 
Chronos~\cite{chronos} targets time-range graph analytics, requiring computation on the sequence of static snapshots of a temporal graph within a time range. An example is analyzing the change of each vertex's PageRank for a given time range. Obviously, the most straightforward approach of applying computation on each snapshot separately is too expensive. Chronos achieves efficiency by exploiting locality of temporal graphs.

\vspace{2mm}

\noindent{\bf In-Memory Graph Layout.} There are two kinds of locality for temporal graphs that can be exploited for efficient data layout: \emph{time} locality, where states of a vertex (or an edge) in consecutive snapshots are stored together; and \emph{structure} locality, where states of neighboring vertices in the same snapshot are laid out close to each other. Due to the complex structure of a graph, structure locality is very hard to achieve. Chronos thus favors time locality for graph layout. The selected snapshots for a temporal graph in a time range are stored together in a vertex data array and an edge array. In the vertex data array, data is grouped by the vertices. The data of a vertex in consecutive snapshots are placed together. In the edge array, all the edges are grouped by the source vertices. Inside each group, every edge stores the target vertex ID and a bitmap indicating the snapshots that contain the edge. 
%Although storing all the snapshots in this aggregate form has some similarity to the aggregate graph concept in TIDE, they are used in different context. TIDE stores sample graphs at the same time point together, whereas Chronos stores snapshots in different time points together.

\vspace{2mm}

\noindent{\bf Scheduling of Graph Computation.} To leverage the time-locality graph layout, Chronos employs the locality-aware batch scheduling (LABS) of graph computation. More specifically, LABS batches the processing of a vertex across all the snapshots, as well as the information propagation to a neighboring vertex for all the snapshots. %This batching is similar to the bulk execution model in TIDE, but again TIDE uses it for different sample graphs at the same time point instead of snapshots at different time points. 
In~\cite{chronos}, the authors show that with a simple partition-by-vertex strategy, LABS significantly improves the performance of graph computation in a multi-core parallel setting.

\vspace{2mm}

\noindent{\bf Incremental Computation.} Since Chronos targets at time-range graph analysis, it benefits more from incremental computation. Besides the incremental approach discussed at the end of Section~\ref{ssec:dynamicOverview}, Chronos proposes two enhancements. First, if the target time-range contains a sequence of $N$ snapshots $S_0$ to $S_{N-1}$, it first computes on $S_0$, and then uses the final states of $S_0$ as the initial states for $S_1$ to $S_{N-1}$, and computes the remaining $N-1$ snapshots in one batch using LABS. In the second enhancement, Chronos pre-computes the intersection (or the union) of the $N$ snapshots, applies graph computation on the intersection (or union) graph first, and then uses the final states of this computation as the initial states for all the snapshots and computes all the snapshots in a batch. The second enhancement allows incremental algorithms designed for edge-insertion only to work with temporal graphs with edge deletion.

\vspace{2mm}

\noindent{\bf On-Disk Graph Layout.} Chronos also leverages the time locality to store temporal graphs on disk in a compact way. The layout is organized in snapshot groups. A snapshot group $G_{t_1,t_2}$ contains the state of $G$ in the time range $[t_1,t_2]$, by including a checkpoint of the snapshot of $G$ at $t_1$ followed by all the updates made till $t_2$. The snapshot group is physically stored as edge files and vertex files in time-locality fashion. For example, an edge file begins with an index to each vertex in the snapshot group, followed by segments of vertex data. The segment of a vertex, in turn, first contains a set of edges associated with the vertex at the start time of the snapshot group, followed by all the edge updates to the vertex. A link structure is further introduced to link edge updates related to the same vertex/edge, so that the state of a vertex/edge at a given time $t$ can be efficiently constructed.

\subsection{DeltaGraph}
The original DeltaGraph~\cite{KhuranaD13:HistoricGraph} system only supported retrieval of individual snapshots of the historical graph as of specific time instances. Here we instead discuss the extension of that work~\cite{KhuranaD16:HistoricGraph} that allows retrieval of different temporal graph primitives including neighborhood versions, node histories, and graph snapshots, and that features a temporal graph analysis framework built on top of Apache Spark. 

\vspace{2mm}
\noindent{\bf Temporal Graph Index.} DeltaGraph organizes the historical graph data in a hierarchical data structure, whose lowest level corresponds
to the snapshots of the network over time, and whose interior nodes correspond to graphs constructed by ``combining''
the lower level snapshots in some fashion; the interior nodes are typically not valid snapshots as of any specific time point. Neither the lowest-level
graph snapshots nor the graphs corresponding to the interior nodes are actually stored explicitly. Instead, for each edge, a {\em delta}, i.e., the
difference between the two graphs corresponding to its endpoints, is computed, and these deltas are explicitly stored. In addition, the graph
corresponding to the root is explicitly stored. Given those, any specific snapshot can be constructed by traversing any
path from the root to the node corresponding to the snapshot in the index, and by appropriately combining the information present in the deltas.
Use of different ``combining'' functions leads to a different point in the performance-storage trade-off, with {\em intersection} being the most
natural such function.  This index structure especially shines with multi-snapshot retrieval queries which are expected to be common in temporal 
analysis, as it can share the computation and retrieval of deltas across the multiple snapshots.
The index structure is also {\bf extensible}, providing a user the opportunity to define additional 
indexes to be created and maintained in order to efficiently execute specific queries (e.g., subgraph pattern matching, reachability, etc.)
    over the historical graph data.

To facilitate distributed storage and parallel retrieval, the deltas themselves are partitioned horizontally by nodes and vertically by attributes 
of the nodes, and these partitions are stored in a key-value store (specifically, Apache Cassandra). This allows efficient retrieval of not only
entire snapshots, but also of individual neighborhoods or temporal histories of individual neighborhoods.

\vspace{2mm}
\noindent{\bf Temporal Graph Analysis Framework.} The second, somewhat orthogonal, component of this system is a Apache Spark-based analysis
framework to specify temporal graph analysis tasks. This analysis framework is based on an abstraction of a \textit{set of nodes 
(or subgraphs) evolving over time}. Several operations are supported on top of this abstraction, including selection, timeslicing, and
temporal {\em map} and {\em reduce} operations. The library is implemented in Python and Java, is built on top of Apache Spark, and also provides
integration with GraphX for executing graph algorithms supported by that system.

\subsection{LLAMA}
So far, we have only reviewed distributed temporal-graph systems. There also exist some single-machine systems that support graph analytics on temporal graphs. In this subsection, we introduce a single-machine system called LLAMA~\cite{llama} for storing and analyzing evolving graphs. LLAMA aims at applications that receive a steady stream of graph updates, but need to perform various whole-graph analysis on consistent views. It is worth mentioning that there also exist some single-machine temporal-graph systems for specific types of graph queries. For example, EAGr~\cite{eagr} is an in-memory system for continuously answering ego-centric aggregate queries on a temporal graph, where a query computes an aggregate in the neighborhood of a vertex over a recent time window.

LLAMA is a single machine system that stores and incrementally updates an evolving graph in multi-version representation, and it supports both in-memory and out-of-core graph analysis on graph snapshots. LLAMA provides a general-purpose programming model, though vertex-centric or edge-centric computations can be implemented on top of it.

In LLAMA, an evolving graph is modeled as a time series of graph snapshots, where each batch of incremental updates produces a new graph snapshot. The graph storage is read-optimized, while the update buffer is write-optimized.

The most important contribution of LLAMA is that, it augments the compact read-only CSR representation to support mutability and persistence. Specifically, a graph is represented by a single vertex table, and multiple edge tables, one per snapshot. The vertex table is organized as a large multi-versioned array (LAMA) that uses a software copy-on-write technique for snapshotting, and the record of each vertex $v$ in the vertex table maintains the necessary information to track $v$'s adjacency list from the edge tables across snapshots.

We now review the LAMA data structure for representing the vertex table. Specifically, the array of records is partitioned into equal-sized data pages, and an indirection array is constructed that contains pointers to the data pages. The indirection array fits in L3 cache. To create a new snapshot, the indirection array is copied, with those references to out-dated pages replaced by those to the newly modified pages. Thus, we do not need to copy unmodified pages across snapshots. LAMA stores 16 consecutive snapshots of the vertex table in each file, so that disk space can be easily reclaimed from deleted snapshots.

The edge table for a snapshot $i$ is organized as a fixed-length array that stores adjacency list fragments consecutively, where each adjacency list fragment contains the edges of a vertex added in snapshot~$i$. An adjacency list fragment of vertex $v$ also stores a continuation record, which points to the next fragment for $v$, or {\em null} if there are no more edges. To support edge deletion, each edge table may maintain a deletion vector, which is an array that encodes in which snapshot an edge was deleted.

Properties on vertices and edges may change and should also support snapshotting. Like the vertex table, each type of property is also stored with a LAMA. Different types of properties are stored in separate LAMAs, so that a job may only load the needed property (or properties) for graph analysis.

LLAMA buffers incoming updates in a write-optimized lookup table, which stores the newly-added and deleted edges for each vertex. The buffered updates are only written into a new snapshot, and a graph analytics query only runs on the read-optimized graph storage without checking the table of buffered updates.



\bibliographystyle{alpha}
\bibliography{sample} %for bibtex-example

%For non-Bibtex users:
%\begin{thebibliography}{99}
%\bibitem[Aron 2001]{Aron01} Aron J, Blass B (2001) The future of modern genomics. Blackwell, London
%\bibitem[Brown 2001]{Brown01} Brown B, Aaron M (2001) The politics of nature. In: Smith J (ed) The rise of modern genomics, 3rd edn. Wiley, New York, p 234 -295 
%\bibitem[Smith 1999] {Smith99} Smith J, Jones M Jr, Houghton L et al (1999) Future of health insurance. N Engl J Med 965:325 -329  
%\bibitem[South 1999]{South99} South M (1999) The future of genomics. In: Williams H (ed) Proceedings of the genomic researchers, Boston, 1999
%\end{thebibliography}

\end{document}
